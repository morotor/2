{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import random\n",
        "import numpy as np\n",
        "import csv\n",
        "import jieba\n",
        "\n",
        "\n",
        "file_path = './data/review.csv'\n",
        "jieba.load_userdict(\"./data/userdict.txt\")\n",
        "\n",
        "\n",
        "def load_corpus(corpus_path):\n",
        "    with open(corpus_path, 'r', encoding = \"utf-8\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        rows = [row for row in reader]\n",
        "\n",
        "    # 将读取出来的语料转为list\n",
        "    review_data = np.array(rows).tolist()\n",
        "    # 打乱语料的顺序\n",
        "    random.shuffle(review_data)\n",
        "\n",
        "    review_list = []\n",
        "    sentiment_list = []\n",
        "    # 第一列为差评/好评， 第二列为评论\n",
        "    for words in review_data:\n",
        "        review_list.append(words[1])\n",
        "        sentiment_list.append(words[0])\n",
        "\n",
        "    return review_list, sentiment_list\n",
        "\n",
        "review_list, sentiment_list = load_corpus(file_path)\n",
        "\n",
        "print(review_list[:10], sentiment_list[:10])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Loading model from cache C:\\Users\\a\\Desktop\\新建文件夹\\2\\111\\data\n",
            "Loading model cost 0.606 seconds.\n",
            "Prefix dict has been built successfully.\n"
           " ##jieba.setLogLevel(jieba.logging.INFO)"
            
            
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['也许是以为太累了 抱歉 我几乎是要睡着了', '没觉得多特别。对我来说，黑泽明和王家卫是一列，蛤蟆的油', '一切喜欢芭蕾的学芭蕾的送孩子学芭蕾的上辈子都是折翼的天使', '没觉得好看', '很经典的一部温情电影 同学一直推荐看，终于找时间看完了。 少年时期的感情永远是那么美好，珍惜吧这最后的青春时光。', '经典中的经典，不过我还真没看出来好在哪儿了……', '摄影加一星。影片本身缺乏凝聚力，几乎为单纯的影像展览。', '永远的紫霞，朱茵最让我惊艳的瞬间。最后看到城楼相拥的二人泪目了。', '治愈系电影，记住了那句生活就像一盒巧克力，开头轻音乐也很好听', '奥黛丽·赫本是荷兰间谍。这部片是制造虚幻美梦的电影。大部分美国电影都是中情局控制下的好莱坞生产的精神鸦片。详情见这本书《好莱坞内部的中情局》http://book.douban.com/subject/26370014'] ['0', '0', '0', '0', '1', '0', '1', '1', '1', '0']\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-29T12:32:11.192Z",
          "iopub.execute_input": "2021-12-29T12:32:11.202Z",
          "iopub.status.idle": "2021-12-29T12:32:13.264Z",
          "shell.execute_reply": "2021-12-29T12:32:13.310Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(review_list) // 5\n",
        "\n",
        "train_review_list, train_sentiment_list = review_list[n:], sentiment_list[n:]\n",
        "test_review_list, test_sentiment_list = review_list[:n], sentiment_list[:n]\n",
        "\n",
        "print('训练集数量： {}'.format(str(len(train_review_list))))\n",
        "print('测试集数量： {}'.format(str(len(test_review_list))))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "训练集数量： 41402\n",
            "测试集数量： 10350\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-29T12:32:13.273Z",
          "iopub.execute_input": "2021-12-29T12:32:13.280Z",
          "iopub.status.idle": "2021-12-29T12:32:13.291Z",
          "shell.execute_reply": "2021-12-29T12:32:13.313Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import jieba\n",
        "\n",
        "\n",
        "stopword_path = './data/stopwords.txt'\n",
        "\n",
        "\n",
        "def load_stopwords(file_path):\n",
        "    stop_words = []\n",
        "    with open(file_path, encoding='UTF-8') as words:\n",
        "       stop_words.extend([i.strip() for i in words.readlines()])\n",
        "    return stop_words\n",
        "\n",
        "\n",
        "def review_to_text(review):\n",
        "    stop_words = load_stopwords(stopword_path)\n",
        "    # 去除英文\n",
        "    review = re.sub(\"[^\\u4e00-\\u9fa5^a-z^A-Z]\", '', review)\n",
        "    review = jieba.cut(review)\n",
        "    # 去掉停用词\n",
        "    if stop_words:\n",
        "        all_stop_words = set(stop_words)\n",
        "        words = [w for w in review if w not in all_stop_words]\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "# 用于训练的评论\n",
        "review_train = [' '.join(review_to_text(review)) for review in train_review_list]\n",
        "# 对于训练评论对应的好评/差评\n",
        "sentiment_train = train_sentiment_list\n",
        "\n",
        "# 用于测试的评论\n",
        "review_test = [' '.join(review_to_text(review)) for review in test_review_list]\n",
        "# 对于测试评论对应的好评/差评\n",
        "sentiment_test = test_sentiment_list\n",
        "print(0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-29T12:32:13.299Z",
          "iopub.execute_input": "2021-12-29T12:32:13.305Z",
          "iopub.status.idle": "2021-12-29T12:32:57.378Z",
          "shell.execute_reply": "2021-12-29T12:32:57.363Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "count_vec = CountVectorizer(max_df=0.8, min_df=3)\n",
        "\n",
        "tfidf_vec = TfidfVectorizer()\n",
        "\n",
        "# 定义Pipeline对全部步骤的流式化封装和管理，可以很方便地使参数集在新数据集（比如测试集）上被重复使用。\n",
        "def MNB_Classifier():\n",
        "    return Pipeline([\n",
        "        ('count_vec', CountVectorizer()),\n",
        "        ('mnb', MultinomialNB())\n",
        "    ])\n",
        "\n",
        "mnbc_clf = MNB_Classifier()\n",
        "print(0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-29T12:32:57.388Z",
          "iopub.execute_input": "2021-12-29T12:32:57.394Z",
          "iopub.status.idle": "2021-12-29T12:32:57.777Z",
          "shell.execute_reply": "2021-12-29T12:32:57.790Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnbc_clf = MNB_Classifier()\n",
        "\n",
        "# 进行训练\n",
        "mnbc_clf.fit(review_train, sentiment_train)\n",
        "\n",
        "# 测试集准确率\n",
        "print('测试集准确率： {}'.format(mnbc_clf.score(review_test, sentiment_test)))\n",
        "print('训练集准确率： {}'.format(mnbc_clf.score(review_train, sentiment_train)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "测试集准确率： 0.7943961352657005\n",
            "训练集准确率： 0.8789430462296507\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-29T12:32:57.807Z",
          "iopub.execute_input": "2021-12-29T12:32:57.820Z",
          "iopub.status.idle": "2021-12-29T12:32:59.044Z",
          "shell.execute_reply": "2021-12-29T12:32:59.058Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(mnbc_clf.predict([\"这是一部关于自由、友情、正义的电影!“信念不灭，希望永存”。这其实是他们全体人的救赎，只是选择的方式不同而已。\"]));"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0']\n"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-29T12:59:12.403Z",
          "iopub.execute_input": "2021-12-29T12:59:12.408Z",
          "iopub.status.idle": "2021-12-29T12:59:12.416Z",
          "shell.execute_reply": "2021-12-29T12:59:12.428Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
